# Fediverse Wrapped Configuration
# Copy this file to .env and customize as needed

# Default year (can be overridden via command line)
DEFAULT_YEAR=2025

# Ollama AI Configuration (optional - skipped if unreachable)
OLLAMA_BASE_URL="http://localhost:11434"
OLLAMA_MODEL="llama3.1:latest"

# Posts per chunk for AI analysis (all posts are analyzed in chunks)
AI_CHUNK_SIZE=50
